{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Audio Features using openSMILE\n",
    "\n",
    "In this notebook, we will demonstrate how to extract audio features from a set of 10 random audio files using openSMILE. OpenSMILE is a popular open-source toolkit for extracting features from audio signals, which is widely used in speech processing and affective computing.\n",
    "\n",
    "## Why openSMILE?\n",
    "openSMILE provides a comprehensive set of audio features, including both low-level descriptors (LLDs) such as pitch, energy, and MFCCs, as well as high-level statistical functionals like means and standard deviations of these LLDs. This makes it a powerful tool for various audio analysis tasks.\n",
    "\n",
    "## Features Extracted\n",
    "We will use the `ComParE_2016` feature set at the `Functionals` level, which includes features such as:\n",
    "- **Loudness**\n",
    "- **MFCCs (Mel-frequency cepstral coefficients)**\n",
    "- **Pitch and voicing related features**\n",
    "- **Spectral features**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audiopath</th>\n",
       "      <th>audio_raw</th>\n",
       "      <th>sr</th>\n",
       "      <th>label</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/data_final/Audios/Tonsill/Raw/aeiou/1/Ton...</td>\n",
       "      <td>[0.00018310547, 9.1552734e-05, 0.00024414062, ...</td>\n",
       "      <td>44100</td>\n",
       "      <td>Tonsill</td>\n",
       "      <td>[1.1715089, 0.705074, 0.24207188, 0.0570324, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/data_final/Audios/Tonsill/U/3/Tonsill_ses...</td>\n",
       "      <td>[0.044189453, 0.04348755, 0.04196167, 0.040832...</td>\n",
       "      <td>44100</td>\n",
       "      <td>Tonsill</td>\n",
       "      <td>[0.31667173, 0.0, 0.98, 0.62788707, 0.643359, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/data_final/Audios/Contr/Brasero/3/Contr_s...</td>\n",
       "      <td>[-0.002532959, -0.0026855469, -0.0010681152, 0...</td>\n",
       "      <td>44100</td>\n",
       "      <td>Contr</td>\n",
       "      <td>[1.2833433, 0.17434211, 0.21052632, 0.43659222...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/data_final/Audios/Fess/U/2/FESS_ses2_u_00...</td>\n",
       "      <td>[0.12445068, 0.12133789, 0.118621826, 0.115386...</td>\n",
       "      <td>44100</td>\n",
       "      <td>Fess</td>\n",
       "      <td>[0.16239512, 0.7586207, 0.41379312, 1.0949354,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/data_final/Audios/Tonsill/A/1/Tonsill_ses...</td>\n",
       "      <td>[0.0047912598, -0.0005493164, -0.0050964355, -...</td>\n",
       "      <td>44100</td>\n",
       "      <td>Tonsill</td>\n",
       "      <td>[0.7659278, 0.083333336, 0.8541667, 1.1094309,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           audiopath  \\\n",
       "0  data/data_final/Audios/Tonsill/Raw/aeiou/1/Ton...   \n",
       "1  data/data_final/Audios/Tonsill/U/3/Tonsill_ses...   \n",
       "2  data/data_final/Audios/Contr/Brasero/3/Contr_s...   \n",
       "3  data/data_final/Audios/Fess/U/2/FESS_ses2_u_00...   \n",
       "4  data/data_final/Audios/Tonsill/A/1/Tonsill_ses...   \n",
       "\n",
       "                                           audio_raw     sr    label  \\\n",
       "0  [0.00018310547, 9.1552734e-05, 0.00024414062, ...  44100  Tonsill   \n",
       "1  [0.044189453, 0.04348755, 0.04196167, 0.040832...  44100  Tonsill   \n",
       "2  [-0.002532959, -0.0026855469, -0.0010681152, 0...  44100    Contr   \n",
       "3  [0.12445068, 0.12133789, 0.118621826, 0.115386...  44100     Fess   \n",
       "4  [0.0047912598, -0.0005493164, -0.0050964355, -...  44100  Tonsill   \n",
       "\n",
       "                                            features  \n",
       "0  [1.1715089, 0.705074, 0.24207188, 0.0570324, 0...  \n",
       "1  [0.31667173, 0.0, 0.98, 0.62788707, 0.643359, ...  \n",
       "2  [1.2833433, 0.17434211, 0.21052632, 0.43659222...  \n",
       "3  [0.16239512, 0.7586207, 0.41379312, 1.0949354,...  \n",
       "4  [0.7659278, 0.083333336, 0.8541667, 1.1094309,...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import opensmile\n",
    "\n",
    "# Path to audio files\n",
    "path_to_audios = 'data/data_final/Audios'\n",
    "\n",
    "# Collecting all .wav audio files\n",
    "audios = []\n",
    "for root, dirs, files in os.walk(path_to_audios):\n",
    "    for name in files:\n",
    "        if name.endswith('.wav'):\n",
    "            audios.append(os.path.join(root, name))\n",
    "\n",
    "# Select 10 random audio files\n",
    "random_audios = random.sample(audios, 10)\n",
    "\n",
    "# Function to read audio\n",
    "def read_audio(path):\n",
    "    y, sr = librosa.load(path, sr=44100)\n",
    "    return y, sr\n",
    "\n",
    "# Creating a DataFrame to hold audio data and features\n",
    "df = pd.DataFrame(columns=['audiopath', 'audio_raw', 'sr', 'label'])\n",
    "df['audiopath'] = random_audios\n",
    "\n",
    "# Get audio data and sample rate\n",
    "df[['audio_raw', 'sr']] = df['audiopath'].apply(lambda x: pd.Series(read_audio(x)))\n",
    "df['label'] = df['audiopath'].apply(lambda x: x.split('/')[3])\n",
    "\n",
    "# Initialize openSMILE feature extractor\n",
    "smile = opensmile.Smile(\n",
    "    feature_set=opensmile.FeatureSet.ComParE_2016,\n",
    "    feature_level=opensmile.FeatureLevel.Functionals,\n",
    ")\n",
    "\n",
    "# Function to extract openSMILE features\n",
    "def extract_features(audio, sr):\n",
    "    result = smile.process_signal(audio, sr)\n",
    "    return result.values.flatten()\n",
    "\n",
    "# Extract features for each audio file and store in DataFrame\n",
    "df['features'] = df.apply(lambda row: extract_features(row['audio_raw'], row['sr']), axis=1)\n",
    "\n",
    "# Display the DataFrame with extracted features\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
